{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13276,
     "status": "ok",
     "timestamp": 1720783246382,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "ADLuew4gny3W",
    "outputId": "524d77d5-0225-4fda-9004-3301af48e6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Rdd [1, 2, 3, 4, 5]\n",
      "Union Rdd [1, 2, 3, 4, 5, 6]\n",
      "Number of elements in Rdd 5\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"RDD Operations\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "rdd1 =sc.parallelize([1, 2, 3])\n",
    "rdd2 =sc.parallelize([4, 5, 6])\n",
    "union_rdd = rdd1.union(rdd2)\n",
    "print(\"Original Rdd\", rdd.collect())\n",
    "print(\"Union Rdd\", union_rdd.collect())\n",
    "count = rdd.count()\n",
    "print(\"Number of elements in Rdd\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56771,
     "status": "ok",
     "timestamp": 1720783199506,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "GpmVvwBZqsPb",
    "outputId": "f90cb617-1464-4eeb-ee00-e0ad0232669c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=88c8b3c7a40f9e5e9efd9f3e960d858e367cca3146907ef431ad753d4ca3d1c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1736,
     "status": "ok",
     "timestamp": 1720783499685,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Q4czwQKPrOPi",
    "outputId": "771a0626-93c3-48d6-b7b7-bf808bbd025e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of elements in Rdd 15\n"
     ]
    }
   ],
   "source": [
    "sum = rdd.reduce(lambda x, y: x + y)\n",
    "print(\"Sum of elements in Rdd\", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1720783543118,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "ZXQhTqvqsIb4",
    "outputId": "25574b19-0dee-4624-8e0d-57e7643504ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 elements in Rdd [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "first3 = rdd.take(3)\n",
    "print(\"First 3 elements in Rdd\", first3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1720783604502,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Gnz37yPpsRoR",
    "outputId": "c19adba1-5ad6-4074-8445-0c2c55766279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element in Rdd 1\n"
     ]
    }
   ],
   "source": [
    "first_element = rdd.first()\n",
    "print(\"First element in Rdd\", first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6761,
     "status": "ok",
     "timestamp": 1720783958016,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "_47OdwImsg-R",
    "outputId": "9a57d73f-3338-4cd8-f38a-76f627835881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Rdd in ascending order [('a', 1), ('a', 3), ('b', 2), ('b', 5), ('c', 4)]\n",
      "Sorted Rdd in descending order [('c', 4), ('b', 2), ('b', 5), ('a', 1), ('a', 3)]\n",
      "a 1\n",
      "a 3\n",
      "b 2\n",
      "b 5\n",
      "c 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "data = [(\"b\", 2), (\"a\",1), (\"a\", 3), (\"c\", 4), (\"b\", 5)]\n",
    "pair_rdd = sc.parallelize(data)\n",
    "sorted_rdd_asc = pair_rdd.sortByKey()\n",
    "sorted_rdd_desc = pair_rdd.sortByKey(ascending=False)\n",
    "print(\"Sorted Rdd in ascending order\", sorted_rdd_asc.collect())\n",
    "print(\"Sorted Rdd in descending order\", sorted_rdd_desc.collect())\n",
    "for key, value in sorted_rdd_asc.collect():\n",
    "    print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1720784258290,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "cnausZbRtuL7",
    "outputId": "decd6d93-e402-49a8-cf2c-9a1cdea0c1a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Rdd [('b', 20), ('a', 10), ('a', 30), ('c', 40), ('b', 50)]\n",
      "b 20\n",
      "a 10\n",
      "a 30\n",
      "c 40\n",
      "b 50\n"
     ]
    }
   ],
   "source": [
    "data = [(\"b\", 2), (\"a\",1), (\"a\", 3), (\"c\", 4), (\"b\", 5)]\n",
    "pair_rdd = sc.parallelize(data)\n",
    "#mapping\n",
    "mapped_rdd = pair_rdd.mapValues(lambda x: x*10)\n",
    "print(\"Mapped Rdd\", mapped_rdd.collect())\n",
    "for key, value in mapped_rdd.collect():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1847,
     "status": "ok",
     "timestamp": 1720784544465,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "HAR6zbAovwfL",
    "outputId": "8a9157b4-bc19-4482-e044-a01420f3888e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:\n",
      "b\n",
      "a\n",
      "a\n",
      "c\n",
      "b\n",
      "Values:\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "data = [(\"b\", 2), (\"a\",1), (\"a\", 3), (\"c\", 4), (\"b\", 5)]\n",
    "pair_rdd = sc.parallelize(data)\n",
    "#get keys\n",
    "keys_rdd= pair_rdd.keys()\n",
    "print(\"Keys:\")\n",
    "for key in keys_rdd.collect():\n",
    "    print(key)\n",
    "\n",
    "values_rdd = pair_rdd.values()\n",
    "print(\"Values:\")\n",
    "for value in values_rdd.collect():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1720784976952,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "JqVibx3Qxdoz",
    "outputId": "20eb44ec-4fbb-4ae9-a93b-5763082ea82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rdd after repartitioning 3\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 3,4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "rdd_repartitioned = rdd.repartition(3)\n",
    "print(\"Rdd after repartitioning\", rdd_repartitioned.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1720785081222,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "1vrCIVXSxs_P",
    "outputId": "efd94eb6-efe5-44d6-8ab5-7d1867cd6a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions before coalesce 5\n",
      "Number of partitions after coalesce 3\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 3,4, 5]\n",
    "rdd = sc.parallelize(data, 5)\n",
    "print(\"Number of partitions before coalesce\", rdd.getNumPartitions())\n",
    "rdd_coalesced = rdd.coalesce(3)\n",
    "print(\"Number of partitions after coalesce\", rdd_coalesced.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q15HPilVzHWy"
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lk8yG9MtzYPq"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"RDD Operations\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "transactions = [\n",
    "    (1, 101),\n",
    "    (1, 102),\n",
    "    (3, 101),\n",
    "    (4, 103),\n",
    "    (5, 102),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdiCPED-1ZLJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "transactions_rdd = sc.parallelize(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tW8S9UwH1r3D"
   },
   "outputs": [],
   "source": [
    "products_mapping = {\n",
    "    101: \"electronics\",\n",
    "    102: \"clothing\",\n",
    "    103: \"groceries\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo_XvyH54kMb"
   },
   "outputs": [],
   "source": [
    "broadcast_products_mapping = sc.broadcast(products_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mgt6mM_e1v3V"
   },
   "outputs": [],
   "source": [
    "def map_product(transactions):\n",
    "    product_id, amount = transactions\n",
    "    product_category = broadcast_products_mapping.value.get(product_id, products_mapping)\n",
    "    return (product_category, amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U8yIAGf2bP7"
   },
   "outputs": [],
   "source": [
    "mapped_transactions_rdd = transactions_rdd.map(map_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "error",
     "timestamp": 1720787249291,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Z8C6Eef82ruL",
    "outputId": "d8278242-b91f-4e20-80fc-754785c3dbc9"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'setCallSite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e1d9f2bd8e71>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_transactions_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1829\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \"\"\"\n\u001b[0;32m-> 1831\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1832\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/traceback_utils.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_site\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'setCallSite'"
     ]
    }
   ],
   "source": [
    "print(mapped_transactions_rdd.collect())\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJofAJsr226i"
   },
   "outputs": [],
   "source": [
    "numbers= [1, 2, 3, 4, 5, 6, 7,8, 9, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2132,
     "status": "ok",
     "timestamp": 1720787141497,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "WF_mfsQl5nRT",
    "outputId": "6dd51ef7-de9a-48b2-ac10-685c6d6086c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even count: 6\n",
      "Odd count: 5\n"
     ]
    }
   ],
   "source": [
    "numbers_rdd = sc.parallelize(numbers)\n",
    "even_count = sc.accumulator(0)\n",
    "odd_count = sc.accumulator(0)\n",
    "def count_even_odd(number):\n",
    "    if number % 2 == 0:\n",
    "        even_count.add(1)\n",
    "    else:\n",
    "        odd_count.add(1)\n",
    "    return number\n",
    "numbers_rdd.foreach(count_even_odd)\n",
    "print(\"Even count:\", even_count.value)\n",
    "print(\"Odd count:\", odd_count.value)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52645,
     "status": "ok",
     "timestamp": 1721045664254,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "ls7bOTw3T-QJ",
    "outputId": "cef93223-f3bc-4326-e48b-e5d96eba3503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=62278015075791cfccc57ba9a80607c5ce3a4612acb05bd5546241fe6e1b0112\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20994,
     "status": "ok",
     "timestamp": 1721045715711,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Ldin948HUSAg",
    "outputId": "f295671e-b171-48c4-97c7-2c487753ece7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read CSV File\n",
    "df = spark.read.csv(\"/content/Book1.xlsx\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1721046283310,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "bMt8BO0VWhih",
    "outputId": "cafaffbb-1b8a-47f5-d094-6715efce608e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PK\u0003\u0004\u0014\u0000\u0006\u0000\\b\u0000\u0000\u0000!\u0000b�h^\u0001\u0000\u0000�\u0004\u0000\u0000\u0013\u0000\\b\u0002[Content_Types].xml �\u0004\u0002(�\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000���N�0\u0010E�H�C�-Jܲ@\\b5��\u0012*Q>�ēƪc[�ii����\u0010B�\u0015j7�\u0012��{2��h�nm���ƻR\\f����U^\u001b7/���%�\u0017\u0019�rZY�\u0014\u001b@1\u0019__�f�\u0000�q��R4D�AJ�\u001ah\u0015\u0016>����V\u0011�ƹ\\f�Z�9����NV�\u00118ʩ�\u0010��\u0013�ji){^��-I\u0004�\"{�\u0016v^�P!XS)bR�r��K�s(�3�`c\u0002�0���\u000e���\u0006��7\u001e",
      "M4\u001a�����ZƐk+�|\\|z�(���P��6\u0015h_-[�@�!���\u0000Pk��\u0016�2n�}�?\u0015�L��� ��%�\u0013\u001c",
      "��\u001bd����dN\u0018\"m: string (nullable = true)\n",
      " |-- �ǞDO97*�~��ɸ8�O�c\u001c",
      "|n��\\a�\u0004E��\u0014�\u0011���B\u0010��!$}�����;{���[����2�\u0006\u0000\u0000��\u0003\u0000PK\u0003\u0004\u0014\u0000\u0006\u0000\\b\u0000\u0000\u0000!\u0000�U0#�\u0000\u0000\u0000L\u0002\u0000\u0000\\v\u0000\\b\u0002_rels/.rels �\u0004\u0002(�\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000��MO�0\\f��H�����ݐ\u0010BKwAH�!T~�I�\u000f���$\u001bݿ'\u001c",
      "\u0010T\u001a�\u0003G�~����<���!��4��\u0012\u0014;#�w����qu\\a*&r�Fq���\u0011v�����GJy(v��*����K��#F��D�\u0010�.W\u001a\\t\u0013�\u001c",
      "�\u0016=��Z�MY�b��\u0001�BS���7��ϛז��: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/Book1.xlsx\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53629,
     "status": "ok",
     "timestamp": 1721302238837,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "sqgvkwm1muUT",
    "outputId": "c943181a-26bb-4eec-c74f-a0cf065f2608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=7ef22a725ed3139aa8cb3a4d94c672a8a3004c7e38a17a549a4d3ba8ca55c3cb\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuHUU7oEmyBd"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7vW49CEnJa8"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"/content/Electric_Vehicle_Population_Data.csv\")\n",
    "df1 = spark.read.csv(\"/content/iris.data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1721302392718,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "gk_h0ozhnNqQ",
    "outputId": "14551dcc-d950-4dfe-e394-9169191e3648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1396,
     "status": "ok",
     "timestamp": 1721302827996,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "gsDGLUv7nhps",
    "outputId": "507fb272-583c-4c0e-f87c-e6179a52c301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "schema = StructType() \\\n",
    "      .add(\"RecordNumber\",IntegerType(),True) \\\n",
    "      .add(\"Zipcode\",IntegerType(),True) \\\n",
    "      .add(\"ZipCodeType\",StringType(),True) \\\n",
    "      .add(\"City\",StringType(),True)\n",
    "\n",
    "\n",
    "df_with_schema = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(schema) \\\n",
    "      .load(\"/content/Electric_Vehicle_Population_Data.csv\")\n",
    "df_with_schema.printSchema()\n",
    "\n",
    "df2 = spark.read.csv(\"/content/iris.data.csv\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwGPQf32oSPk"
   },
   "outputs": [],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    " .csv(\"/tmp/spark_output/zipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1721303083109,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "pWhrAte6pps0",
    "outputId": "55a7a449-aa6b-4fce-8b0a-eaca977acbb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmptyRDD[33] at emptyRDD at NativeMethodAccessorImpl.java:0\n",
      "ParallelCollectionRDD[34] at readRDDFromFile at PythonRDD.scala:289\n"
     ]
    }
   ],
   "source": [
    "emptyRDD = spark.sparkContext.emptyRDD()\n",
    "print(emptyRDD)\n",
    "rdd2 = spark.sparkContext.parallelize([])\n",
    "print(rdd2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPadrDe0qK3z"
   },
   "outputs": [],
   "source": [
    "#creating empty dataframe with schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "schema = StructType([\n",
    "  StructField('firstname', StringType(), True),\n",
    "  StructField('middlename', StringType(), True),\n",
    "  StructField('lastname', StringType(), True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1490,
     "status": "ok",
     "timestamp": 1721303323155,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "XubR5Am6q0kE",
    "outputId": "5cfe6b57-8534-4f9f-8730-a46a59ffa1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "+---------+----------+--------+\n",
      "|firstname|middlename|lastname|\n",
      "+---------+----------+--------+\n",
      "+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now create empty Rdd  created above and pass it\n",
    "df = spark.createDataFrame(data=emptyRDD,schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1721303582938,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "7jymlJj0rLwF",
    "outputId": "fa33e3c7-8bf7-4c83-f081-0bd9fc17b437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = emptyRDD.toDF(schema)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1721303865865,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "pVkRKbA4sZKc",
    "outputId": "ed0651c7-4c42-4618-ae93-67d8e6b3a7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "+---------+----------+--------+\n",
      "|firstname|middlename|lastname|\n",
      "+---------+----------+--------+\n",
      "+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#here we create it manually with schema and without RDD\n",
    "df2 = spark.createDataFrame([], schema)\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1878,
     "status": "ok",
     "timestamp": 1721303855457,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "nZHAlQRusdN0",
    "outputId": "c5dfa585-0367-4422-8982-0ba1172a6b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame([], StructType([]))\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slYEmqZgsipb"
   },
   "outputs": [],
   "source": [
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M', 4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F', 4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F', -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMbCkeYYt9vM"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1721304616771,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "bbdot_A7vzum",
    "outputId": "7da3577e-e016-49e6-d152-5e68518dcfc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+------+\n",
      "|name                |dob       |gender|salary|\n",
      "+--------------------+----------+------+------+\n",
      "|{James, , Smith}    |1991-04-01|M     |3000  |\n",
      "|{Michael, Rose, }   |2000-05-19|M     |4000  |\n",
      "|{Robert, , Williams}|1978-09-05|M     |4000  |\n",
      "|{Maria, Anne, Jones}|1967-12-01|F     |4000  |\n",
      "|{Jen, Mary, Brown}  |1980-02-17|F     |-1    |\n",
      "+--------------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "df = spark.createDataFrame(data=dataDF, schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1721304776431,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "1wikKy0XwcDF",
    "outputId": "54ba242f-2bb7-4353-a772-bbcaa79a3f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#direct printschema\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1721304962576,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "DqOdDWDhwyO9",
    "outputId": "70aa1993-46dd-46f1-de86-cb5bb2b96757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----------+------+-------------+\n",
      "|name                |DateOfBirth|gender|salary_amount|\n",
      "+--------------------+-----------+------+-------------+\n",
      "|{James, , Smith}    |1991-04-01 |M     |3000         |\n",
      "|{Michael, Rose, }   |2000-05-19 |M     |4000         |\n",
      "|{Robert, , Williams}|1978-09-05 |M     |4000         |\n",
      "|{Maria, Anne, Jones}|1967-12-01 |F     |4000         |\n",
      "|{Jen, Mary, Brown}  |1980-02-17 |F     |-1           |\n",
      "+--------------------+-----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to change multiple column name\n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\").withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1721305677642,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "DkbszexKzDHm",
    "outputId": "90a8a495-cbce-453b-fd99-cf7e541296b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- midname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(col(\"name.firstname\").alias(\"fname\"), \\\n",
    "          col(\"name.middlename\").alias(\"midname\"), \\\n",
    "          col(\"name.lastname\").alias(\"lname\"), \\\n",
    "          col(\"dob\").alias(\"date_of_birth\"), \\\n",
    "          col(\"gender\").alias(\"gender\"), \\\n",
    "          col(\"salary\").alias(\"salary\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63474,
     "status": "ok",
     "timestamp": 1721394977807,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "_Nrlg2ziIJ35",
    "outputId": "0ef6526c-0699-42b7-fdfd-aff2d98c16ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=6c8fe76474f833b42c79ab92debde607b30f9174d4d1de6b68d1a80f717a1cde\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9828,
     "status": "ok",
     "timestamp": 1721395676675,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "z9Y0yMDfIaC5",
    "outputId": "8da9c5e0-450d-484d-b8bc-9b3fe617af3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+------+\n",
      "|name                |dob       |gender|salary|\n",
      "+--------------------+----------+------+------+\n",
      "|{James, , Smith}    |1991-04-01|M     |3000  |\n",
      "|{Michael, Rose, }   |2000-05-19|M     |4000  |\n",
      "|{Robert, , Williams}|1978-09-05|M     |4000  |\n",
      "|{Maria, Anne, Jones}|1967-12-01|F     |4000  |\n",
      "|{Jen, Mary, Brown}  |1980-02-17|F     |-1    |\n",
      "+--------------------+----------+------+------+\n",
      "\n",
      "root\n",
      " |-- newCol1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- newCol2: string (nullable = true)\n",
      " |-- newCol3: string (nullable = true)\n",
      " |-- newCol4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rewritten whole code again\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M', 4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F', 4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F', -1)]\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "df = spark.createDataFrame(data=dataDF, schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "#new code\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1761,
     "status": "ok",
     "timestamp": 1721395990628,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "tQBSwLgxLapi",
    "outputId": "ed59683f-8a31-4ed4-bc89-6846bafad409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- _1: string (nullable = true)\n",
      " |    |-- _2: string (nullable = true)\n",
      " |    |-- _3: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+------+\n",
      "|name                |dob       |gender|salary|\n",
      "+--------------------+----------+------+------+\n",
      "|{James, , Smith}    |1991-04-01|M     |3000  |\n",
      "|{Michael, Rose, }   |2000-05-19|M     |4000  |\n",
      "|{Robert, , Williams}|1978-09-05|M     |4000  |\n",
      "|{Maria, Anne, Jones}|1967-12-01|F     |4000  |\n",
      "|{Jen, Mary, Brown}  |1980-02-17|F     |5000  |\n",
      "+--------------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M', 4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F', 4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F', 5000)]\n",
    "columns = [\"name\", \"dob\", \"gender\", \"salary\"]\n",
    "df = spark.createDataFrame(data=dataDF, schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1721396119514,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "jjXlNV6aMpoS",
    "outputId": "79e6c53f-58bc-495c-dcf2-ebd1ecef750f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+------+----------+\n",
      "|                name|       dob|gender|salary|new_salary|\n",
      "+--------------------+----------+------+------+----------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|      3000|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|      4000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|      4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|      4000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|  5000|      5000|\n",
      "+--------------------+----------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.withColumn(\"new_salary\", col(\"salary\").cast(\"integer\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2152,
     "status": "ok",
     "timestamp": 1721396147653,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "80l2O6VLNFKz",
    "outputId": "f33311e1-6f70-4df2-ba9b-8c4508760c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+------+----------+\n",
      "|                name|       dob|gender|salary|new_salary|\n",
      "+--------------------+----------+------+------+----------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|    300000|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|    400000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|    400000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|    400000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|  5000|    500000|\n",
      "+--------------------+----------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"new_salary\", col(\"salary\")*100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1721396167632,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Ra8D7fdCNFKL",
    "outputId": "fbaa69e7-0655-4d00-e38b-ff717c5d10f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- _1: string (nullable = true)\n",
      " |    |-- _2: string (nullable = true)\n",
      " |    |-- _3: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1314,
     "status": "ok",
     "timestamp": 1721396551158,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "4MxiNK7wNP_L",
    "outputId": "ae52dd1f-524f-413f-a696-aa65c417ba25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+------+-------------+\n",
      "|                name|       dob|gender|salary|Copied Column|\n",
      "+--------------------+----------+------+------+-------------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|        -3000|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|        -4000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|        -4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|        -4000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|  5000|        -5000|\n",
      "+--------------------+----------+------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Copied Column\", col(\"salary\")*-1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1511,
     "status": "ok",
     "timestamp": 1721396898795,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "P_iBJ-48PWm7",
    "outputId": "f1ffe49d-3bbc-4d46-fb07-01ca98bf3f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+------+-------+\n",
      "|                name|       dob|gender|salary|Country|\n",
      "+--------------------+----------+------+------+-------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|    USA|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|    USA|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|    USA|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|    USA|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|  5000|    USA|\n",
      "+--------------------+----------+------+------+-------+\n",
      "\n",
      "+--------------------+----------+------+------+-------+----------------+\n",
      "|                name|       dob|gender|salary|Country|Years of working|\n",
      "+--------------------+----------+------+------+-------+----------------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|    USA|           10yrs|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|    USA|           10yrs|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|    USA|           10yrs|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|    USA|           10yrs|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|  5000|    USA|           10yrs|\n",
      "+--------------------+----------+------+------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "df.withColumn(\"Country\", lit(\"USA\")).show()\n",
    "df.withColumn(\"Country\", lit(\"USA\")) \\\n",
    "  .withColumn(\"Years of working\", lit(\"10yrs\")) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1721397098733,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "j5FyZuwBQoht",
    "outputId": "eb09121e-e608-4370-f6ed-49c8783c267b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---+------+\n",
      "|                name|       dob|sex|salary|\n",
      "+--------------------+----------+---+------+\n",
      "|    {James, , Smith}|1991-04-01|  M|  3000|\n",
      "|   {Michael, Rose, }|2000-05-19|  M|  4000|\n",
      "|{Robert, , Williams}|1978-09-05|  M|  4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|  F|  4000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|  F|  5000|\n",
      "+--------------------+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"gender\",\"sex\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1721397193213,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "ywb-I9RWRAdc",
    "outputId": "f52a44e4-cfd0-4fc8-f4f4-7d550f718dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+\n",
      "|                name|gender|salary|\n",
      "+--------------------+------+------+\n",
      "|    {James, , Smith}|     M|  3000|\n",
      "|   {Michael, Rose, }|     M|  4000|\n",
      "|{Robert, , Williams}|     M|  4000|\n",
      "|{Maria, Anne, Jones}|     F|  4000|\n",
      "|  {Jen, Mary, Brown}|     F|  5000|\n",
      "+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"dob\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1125,
     "status": "ok",
     "timestamp": 1721397586148,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "lXYrWAd4RMHM",
    "outputId": "3371b1cc-8670-40c4-cb47-219aae14efed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Amount: long (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "|Banana |1000  |USA    |\n",
      "|Carrots|1500  |USA    |\n",
      "|Beans  |1600  |USA    |\n",
      "|Orange |2000  |USA    |\n",
      "|Orange |2000  |USA    |\n",
      "|Banana |400   |China  |\n",
      "|Carrots|1200  |China  |\n",
      "|Beans  |1500  |China  |\n",
      "|Orange |4000  |China  |\n",
      "|Banana |2000  |Canada |\n",
      "|Carrots|2000  |Canada |\n",
      "|Beans  |2000  |Mexico |\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "data=[(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000, \"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5810,
     "status": "ok",
     "timestamp": 1721397885636,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "LpIHfTRNTscN",
    "outputId": "b2e8ffdc-0e84-495d-a354-92e22b32dad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Canada: long (nullable = true)\n",
      " |-- China: long (nullable = true)\n",
      " |-- Mexico: long (nullable = true)\n",
      " |-- USA: long (nullable = true)\n",
      "\n",
      "+-------+------+-----+------+----+\n",
      "|Product|Canada|China|Mexico|USA |\n",
      "+-------+------+-----+------+----+\n",
      "|Orange |NULL  |4000 |NULL  |4000|\n",
      "|Beans  |NULL  |1500 |2000  |1600|\n",
      "|Banana |2000  |400  |NULL  |1000|\n",
      "|Carrots|2000  |1200 |NULL  |1500|\n",
      "+-------+------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2945,
     "status": "ok",
     "timestamp": 1721398211418,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "8-cnM2BAU4B9",
    "outputId": "5de367ab-0a3a-47a5-e19a-222da624b05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+------+------+\n",
      "|Product|USA |China|Canada|Mexico|\n",
      "+-------+----+-----+------+------+\n",
      "|Orange |4000|4000 |NULL  |NULL  |\n",
      "|Beans  |1600|1500 |NULL  |2000  |\n",
      "|Banana |1000|400  |2000  |NULL  |\n",
      "|Carrots|1500|1200 |2000  |NULL  |\n",
      "+-------+----+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries = [\"USA\",\"China\",\"Canada\",\"Mexico\"]\n",
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\", countries).sum(\"Amount\")\n",
    "pivotDF.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3619,
     "status": "ok",
     "timestamp": 1721398307461,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "hCXqxnFIVCVU",
    "outputId": "d63c527c-b638-478d-9776-393058b90623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+------+----+\n",
      "|Product|Canada|China|Mexico|USA |\n",
      "+-------+------+-----+------+----+\n",
      "|Orange |NULL  |4000 |NULL  |4000|\n",
      "|Beans  |NULL  |1500 |2000  |1600|\n",
      "|Banana |2000  |400  |NULL  |1000|\n",
      "|Carrots|2000  |1200 |NULL  |1500|\n",
      "+-------+------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivotDF = df.groupBy(\"Product\",\"Country\") \\\n",
    "      .sum(\"Amount\") \\\n",
    "      .groupBy(\"Product\") \\\n",
    "      .pivot(\"Country\") \\\n",
    "      .sum(\"sum(Amount)\")\n",
    "pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3578,
     "status": "ok",
     "timestamp": 1721398888437,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Y-_3NqyDVZnG",
    "outputId": "35a0d181-88f9-4c83-a31f-2245db345698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Product|Country|Total|\n",
      "+-------+-------+-----+\n",
      "|Orange |China  |4000 |\n",
      "|Beans  |China  |1500 |\n",
      "|Beans  |Mexico |2000 |\n",
      "|Banana |Canada |2000 |\n",
      "|Banana |China  |400  |\n",
      "|Carrots|Canada |2000 |\n",
      "|Carrots|China  |1200 |\n",
      "+-------+-------+-----+\n",
      "\n",
      "+-------+-------+-----+\n",
      "|Product|Country|Total|\n",
      "+-------+-------+-----+\n",
      "| Orange|  China| 4000|\n",
      "|  Beans|  China| 1500|\n",
      "|  Beans| Mexico| 2000|\n",
      "| Banana| Canada| 2000|\n",
      "| Banana|  China|  400|\n",
      "|Carrots| Canada| 2000|\n",
      "|Carrots|  China| 1200|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "unpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\n",
    "unPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n",
    "    .where(\"Total is not null\")\n",
    "unPivotDF.show(truncate=False)\n",
    "unPivotDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1721399533195,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Yp4Gwf9kZf2Z",
    "outputId": "37ccabd9-2ab6-49bd-c812-5f5940bda005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "# Check if 'spark' is already defined and rename if necessary\n",
    "if 'spark' in locals() and isinstance(spark, SparkSession):\n",
    "    spark_session = spark  # Rename existing SparkSession\n",
    "else:\n",
    "    spark_session = SparkSession.builder.master(\"local[1]\") \\\n",
    "        .appName(\"SparkByExamples.com\") \\\n",
    "        .getOrCreate()  # Create new SparkSession\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "                      StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    "\n",
    "df = spark_session.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49940,
     "status": "ok",
     "timestamp": 1721996143483,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "ggfqlJUY9vV-",
    "outputId": "2161a3ef-abd5-4d9f-bda6-3fd110aa1ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=328b00014a6ed681743a11c8a470ed4d8396d400ba3dd9ba042746446230409b\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XGT6JBd9Qp2"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19787,
     "status": "ok",
     "timestamp": 1721996587391,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "FT9N0lHL9oXO",
    "outputId": "12e5f0e1-9871-4090-e291-5cd6ece742e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'spark' in locals() and isinstance(spark, SparkSession):\n",
    "    spark_session = spark  # Rename existing SparkSession\n",
    "else:\n",
    "    spark_session = SparkSession.builder.master(\"local[1]\") \\\n",
    "        .appName(\"SparkByExamples.com\") \\\n",
    "        .getOrCreate()  # Create new SparkSession\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "                      StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    "df2 = spark_session.createDataFrame(data=data,schema=schema) # Use 'spark_session' instead of 'spark'\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1677,
     "status": "ok",
     "timestamp": 1721996659521,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "EUFzb9Vo_sN_",
    "outputId": "07bf3e53-dd70-496e-ce2d-bbe5a8e36500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- OtherInfo: struct (nullable = false)\n",
      " |    |-- identifier: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- Salary_Grade: string (nullable = false)\n",
      "\n",
      "+---------+----------+--------+------------------------+\n",
      "|firstname|middlename|lastname|OtherInfo               |\n",
      "+---------+----------+--------+------------------------+\n",
      "|James    |          |Smith   |{36636, M, 3000, Medium}|\n",
      "|Michael  |Rose      |        |{40288, M, 4000, High}  |\n",
      "|Robert   |          |Williams|{42114, M, 4000, High}  |\n",
      "|Maria    |Anne      |Jones   |{39192, F, 4000, High}  |\n",
      "|Jen      |Mary      |Brown   |{, F, -1, Low}          |\n",
      "+---------+----------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,struct, when\n",
    "updatedDF = df2.withColumn(\"OtherInfo\",\n",
    "   struct(col(\"id\").alias(\"identifier\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1144,
     "status": "ok",
     "timestamp": 1722000270669,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "xVpXap70AG_H",
    "outputId": "3b4f7551-33ec-4dec-b74b-598034e78dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data=[(\"James\",\"Sales\",3000),(\"Michael\",\"Sales\",4600),\n",
    "      (\"Robert\",\"Sales\",4100),(\"Maria\",\"Finance\",3000),\n",
    "      (\"James\",\"Sales\",3000),(\"Scott\",\"Finance\",3300),\n",
    "      (\"Jen\",\"Finance\",3900),(\"Jeff\",\"Marketing\",3000),\n",
    "      (\"Kumar\",\"Marketing\",2000),(\"Saif\",\"Sales\",4100)]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = [\"employee_name\",\"department\",\"salary\"])\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2827,
     "status": "ok",
     "timestamp": 1722000642701,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "AjXV_GEpN6d3",
    "outputId": "c827835b-aa25-45db-d668-cc5a66203a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|        James|     Sales|  3000|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "w2  = Window.partitionBy(\"department\").orderBy(col(\"salary\"))\n",
    "df.withColumn(\"row\",row_number().over(w2))\\\n",
    "    .filter(col(\"row\")==1).drop(\"row\") \\\n",
    "    .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1722001311736,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "5OuJtvPCRhU2",
    "outputId": "334d79fa-35ec-4e66-d43d-2052874ef6b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|Department|Salary|\n",
      "+-------------+----------+------+\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|        James|     Sales|  3000|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select employee_name, Department, Salary from\" +\n",
    "          \"(select * ,row_number() OVER (PARTITION BY department ORDER BY salary)as rn \"+\n",
    "          \"From EMP)tmp where rn = 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1170,
     "status": "ok",
     "timestamp": 1722001528187,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "DH7J_QhESaUI",
    "outputId": "4077139f-46a2-46bd-a92a-a3cff3bd272a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|          Jen|   Finance|  3900|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|      Michael|     Sales|  4600|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w3 = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "df.withColumn(\"row\", row_number().over(w3)) \\\n",
    "    .filter(col(\"row\") == 1).drop(\"row\") \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2939,
     "status": "ok",
     "timestamp": 1722001537482,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "6VBTLsuKRhD_",
    "outputId": "f7dd5d70-b75d-460a-ba57-e1b607f67210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----+----+----+\n",
      "|department|   avg|  sum| min| max|\n",
      "+----------+------+-----+----+----+\n",
      "|   Finance|3400.0|10200|3000|3900|\n",
      "| Marketing|2500.0| 5000|2000|3000|\n",
      "|     Sales|3760.0|18800|3000|4600|\n",
      "+----------+------+-----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, row_number,avg,sum,min,max,dense_rank\n",
    "\n",
    "w4 = Window.partitionBy(\"department\")\n",
    "df.withColumn(\"row\",row_number().over(w3)) \\\n",
    "  .withColumn(\"avg\", avg(col(\"salary\")).over(w4)) \\\n",
    "  .withColumn(\"sum\", sum(col(\"salary\")).over(w4)) \\\n",
    "  .withColumn(\"min\", min(col(\"salary\")).over(w4)) \\\n",
    "  .withColumn(\"max\", max(col(\"salary\")).over(w4)) \\\n",
    "  .where(col(\"row\")==1).select(\"department\",\"avg\",\"sum\",\"min\",\"max\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1177,
     "status": "ok",
     "timestamp": 1722001742235,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Es_c2BL5Skqo",
    "outputId": "4425723d-4644-48ce-af7f-69ac9d96111f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,100000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,200000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30, 230000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,230000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,24,240000)]\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2201,
     "status": "ok",
     "timestamp": 1722001960546,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "rOvz8GksTbog",
    "outputId": "23701f31-837c-4a90-d582-22e0eb303ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"department\",\"state\").show(truncate=False)\n",
    "df.sort(col(\"department\"),col(\"state\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1493,
     "status": "ok",
     "timestamp": 1722001992012,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "lMzTt88PULdH",
    "outputId": "f31742be-b4b7-4693-effe-d55aee9d78a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.department.asc(),df.state.asc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1571,
     "status": "ok",
     "timestamp": 1722002105483,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "CdPwgfvUUb8I",
    "outputId": "63f15d8e-26c7-4d7c-fef5-2d01c31bd7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.department.asc(),df.state.asc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").asc()).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1657,
     "status": "ok",
     "timestamp": 1722002333822,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "Pr2G8QO6UvJA",
    "outputId": "915ab03e-5861-420f-ec23-b7fd75852d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.department.asc(),df.state.desc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1160,
     "status": "ok",
     "timestamp": 1722002579836,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "8D0905ZRVpjo",
    "outputId": "67a4987a-b4e6-4fc4-cf07-0a33f1e74478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+------+\n",
      "|employee_name|department|state|salary|age|bonus |\n",
      "+-------------+----------+-----+------+---+------+\n",
      "|James        |Sales     |NY   |90000 |34 |100000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |200000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |230000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |230000|\n",
      "|Raman        |Finance   |CA   |99000 |24 |240000|\n",
      "+-------------+----------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select employee_name,department,state,salary,age,bonus from EMP\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2781,
     "status": "ok",
     "timestamp": 1722003325522,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "c_UgowXEWixw",
    "outputId": "4ff9041e-f48d-4576-d874-76928bff45ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Vehicle Primary Use: string (nullable = true)\n",
      " |-- Battery Electric Vehicles (BEVs): string (nullable = true)\n",
      " |-- Plug-In Hybrid Electric Vehicles (PHEVs): string (nullable = true)\n",
      " |-- Electric Vehicle (EV) Total: string (nullable = true)\n",
      " |-- Non-Electric Vehicle Total: string (nullable = true)\n",
      " |-- Total Vehicles: string (nullable = true)\n",
      " |-- Percent Electric Vehicles: double (nullable = true)\n",
      "\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|             Date|        County|State|Vehicle Primary Use|Battery Electric Vehicles (BEVs)|Plug-In Hybrid Electric Vehicles (PHEVs)|Electric Vehicle (EV) Total|Non-Electric Vehicle Total|Total Vehicles|Percent Electric Vehicles|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|September 30 2022|     Riverside|   CA|          Passenger|                               7|                                       0|                          7|                       460|           467|                      1.5|\n",
      "| December 31 2022|Prince William|   VA|          Passenger|                               1|                                       2|                          3|                       188|           191|                     1.57|\n",
      "|  January 31 2020|        Dakota|   MN|          Passenger|                               0|                                       1|                          1|                        32|            33|                     3.03|\n",
      "|     June 30 2022|         Ferry|   WA|              Truck|                               0|                                       0|                          0|                     3,575|         3,575|                      0.0|\n",
      "|     July 31 2021|       Douglas|   CO|          Passenger|                               0|                                       1|                          1|                        83|            84|                     1.19|\n",
      "|      May 31 2018|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        59|            60|                     1.67|\n",
      "| November 30 2017|   Northampton|   PA|          Passenger|                               0|                                       1|                          1|                        66|            67|                     1.49|\n",
      "|    March 31 2018|        Nassau|   NY|          Passenger|                               1|                                       0|                          1|                        37|            38|                     2.63|\n",
      "|    March 31 2020|        DeKalb|   IN|          Passenger|                               1|                                       0|                          1|                         1|             2|                     50.0|\n",
      "|  January 31 2019|      Columbia|   WA|              Truck|                               0|                                       0|                          0|                     1,529|         1,529|                      0.0|\n",
      "| February 28 2017|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        73|            74|                     1.35|\n",
      "|September 30 2017|       Orleans|   LA|          Passenger|                               0|                                       1|                          1|                        45|            46|                     2.17|\n",
      "| December 31 2018|        Ramsey|   MN|          Passenger|                               1|                                       0|                          1|                        41|            42|                     2.38|\n",
      "| November 30 2020|      Manassas|   VA|          Passenger|                               0|                                       1|                          1|                         5|             6|                    16.67|\n",
      "| February 29 2020|    Montgomery|   AL|          Passenger|                               0|                                       1|                          1|                        38|            39|                     2.56|\n",
      "|   August 31 2019|     Albemarle|   VA|          Passenger|                               1|                                       0|                          1|                        23|            24|                     4.17|\n",
      "|      May 31 2020|        Monroe|   IL|          Passenger|                               1|                                       0|                          1|                         3|             4|                     25.0|\n",
      "| December 31 2021|     San Diego|   CA|          Passenger|                              17|                                       6|                         23|                     2,541|         2,564|                      0.9|\n",
      "|     June 30 2021|      Skamania|   WA|              Truck|                               0|                                       0|                          0|                     4,026|         4,026|                      0.0|\n",
      "|  January 31 2017|       Douglas|   WA|              Truck|                               0|                                       0|                          0|                    11,425|        11,425|                      0.0|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark : SparkSession = SparkSession.builder.master(\"local[1]\") \\\n",
    "        .appName(\"SparkByExamples.com\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "filePath = \"/content/electric vehicle.csv\"\n",
    "df = spark.read.options(header='True', inferSchema='True') \\\n",
    "          .csv(filePath)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1722003332295,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "TQo76Lw-YYxQ",
    "outputId": "76245105-1f76-4d59-c575-d0066542a6a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|             Date|        County|State|Vehicle Primary Use|Battery Electric Vehicles (BEVs)|Plug-In Hybrid Electric Vehicles (PHEVs)|Electric Vehicle (EV) Total|Non-Electric Vehicle Total|Total Vehicles|Percent Electric Vehicles|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|September 30 2022|     Riverside|   CA|          Passenger|                               7|                                       0|                          7|                       460|           467|                      1.5|\n",
      "| December 31 2022|Prince William|   VA|          Passenger|                               1|                                       2|                          3|                       188|           191|                     1.57|\n",
      "|  January 31 2020|        Dakota|   MN|          Passenger|                               0|                                       1|                          1|                        32|            33|                     3.03|\n",
      "|     June 30 2022|         Ferry|   WA|              Truck|                               0|                                       0|                          0|                     3,575|         3,575|                      0.0|\n",
      "|     July 31 2021|       Douglas|   CO|          Passenger|                               0|                                       1|                          1|                        83|            84|                     1.19|\n",
      "|      May 31 2018|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        59|            60|                     1.67|\n",
      "| November 30 2017|   Northampton|   PA|          Passenger|                               0|                                       1|                          1|                        66|            67|                     1.49|\n",
      "|    March 31 2018|        Nassau|   NY|          Passenger|                               1|                                       0|                          1|                        37|            38|                     2.63|\n",
      "|    March 31 2020|        DeKalb|   IN|          Passenger|                               1|                                       0|                          1|                         1|             2|                     50.0|\n",
      "|  January 31 2019|      Columbia|   WA|              Truck|                               0|                                       0|                          0|                     1,529|         1,529|                      0.0|\n",
      "| February 28 2017|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        73|            74|                     1.35|\n",
      "|September 30 2017|       Orleans|   LA|          Passenger|                               0|                                       1|                          1|                        45|            46|                     2.17|\n",
      "| December 31 2018|        Ramsey|   MN|          Passenger|                               1|                                       0|                          1|                        41|            42|                     2.38|\n",
      "| November 30 2020|      Manassas|   VA|          Passenger|                               0|                                       1|                          1|                         5|             6|                    16.67|\n",
      "| February 29 2020|    Montgomery|   AL|          Passenger|                               0|                                       1|                          1|                        38|            39|                     2.56|\n",
      "|   August 31 2019|     Albemarle|   VA|          Passenger|                               1|                                       0|                          1|                        23|            24|                     4.17|\n",
      "|      May 31 2020|        Monroe|   IL|          Passenger|                               1|                                       0|                          1|                         3|             4|                     25.0|\n",
      "| December 31 2021|     San Diego|   CA|          Passenger|                              17|                                       6|                         23|                     2,541|         2,564|                      0.9|\n",
      "|     June 30 2021|      Skamania|   WA|              Truck|                               0|                                       0|                          0|                     4,026|         4,026|                      0.0|\n",
      "|  January 31 2017|       Douglas|   WA|              Truck|                               0|                                       0|                          0|                    11,425|        11,425|                      0.0|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1722003333420,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "N9meOT_VY5QA",
    "outputId": "a2e32a19-7223-4a97-b360-b3da8138e677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|             Date|        County|State|Vehicle Primary Use|Battery Electric Vehicles (BEVs)|Plug-In Hybrid Electric Vehicles (PHEVs)|Electric Vehicle (EV) Total|Non-Electric Vehicle Total|Total Vehicles|Percent Electric Vehicles|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|September 30 2022|     Riverside|   CA|          Passenger|                               7|                                       0|                          7|                       460|           467|                      1.5|\n",
      "| December 31 2022|Prince William|   VA|          Passenger|                               1|                                       2|                          3|                       188|           191|                     1.57|\n",
      "|  January 31 2020|        Dakota|   MN|          Passenger|                               0|                                       1|                          1|                        32|            33|                     3.03|\n",
      "|     June 30 2022|         Ferry|   WA|              Truck|                               0|                                       0|                          0|                     3,575|         3,575|                      0.0|\n",
      "|     July 31 2021|       Douglas|   CO|          Passenger|                               0|                                       1|                          1|                        83|            84|                     1.19|\n",
      "|      May 31 2018|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        59|            60|                     1.67|\n",
      "| November 30 2017|   Northampton|   PA|          Passenger|                               0|                                       1|                          1|                        66|            67|                     1.49|\n",
      "|    March 31 2018|        Nassau|   NY|          Passenger|                               1|                                       0|                          1|                        37|            38|                     2.63|\n",
      "|    March 31 2020|        DeKalb|   IN|          Passenger|                               1|                                       0|                          1|                         1|             2|                     50.0|\n",
      "|  January 31 2019|      Columbia|   WA|              Truck|                               0|                                       0|                          0|                     1,529|         1,529|                      0.0|\n",
      "| February 28 2017|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        73|            74|                     1.35|\n",
      "|September 30 2017|       Orleans|   LA|          Passenger|                               0|                                       1|                          1|                        45|            46|                     2.17|\n",
      "| December 31 2018|        Ramsey|   MN|          Passenger|                               1|                                       0|                          1|                        41|            42|                     2.38|\n",
      "| November 30 2020|      Manassas|   VA|          Passenger|                               0|                                       1|                          1|                         5|             6|                    16.67|\n",
      "| February 29 2020|    Montgomery|   AL|          Passenger|                               0|                                       1|                          1|                        38|            39|                     2.56|\n",
      "|   August 31 2019|     Albemarle|   VA|          Passenger|                               1|                                       0|                          1|                        23|            24|                     4.17|\n",
      "|      May 31 2020|        Monroe|   IL|          Passenger|                               1|                                       0|                          1|                         3|             4|                     25.0|\n",
      "| December 31 2021|     San Diego|   CA|          Passenger|                              17|                                       6|                         23|                     2,541|         2,564|                      0.9|\n",
      "|     June 30 2021|      Skamania|   WA|              Truck|                               0|                                       0|                          0|                     4,026|         4,026|                      0.0|\n",
      "|  January 31 2017|       Douglas|   WA|              Truck|                               0|                                       0|                          0|                    11,425|        11,425|                      0.0|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1722003363242,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "8YhLcBTnZatJ",
    "outputId": "acdf20de-498e-46d1-f628-c5341769e915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|             Date|        County|State|Vehicle Primary Use|Battery Electric Vehicles (BEVs)|Plug-In Hybrid Electric Vehicles (PHEVs)|Electric Vehicle (EV) Total|Non-Electric Vehicle Total|Total Vehicles|Percent Electric Vehicles|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|September 30 2022|     Riverside|   CA|          Passenger|                               7|                                       0|                          7|                       460|           467|                      1.5|\n",
      "| December 31 2022|Prince William|   VA|          Passenger|                               1|                                       2|                          3|                       188|           191|                     1.57|\n",
      "|  January 31 2020|        Dakota|   MN|          Passenger|                               0|                                       1|                          1|                        32|            33|                     3.03|\n",
      "|     June 30 2022|         Ferry|   WA|              Truck|                               0|                                       0|                          0|                     3,575|         3,575|                      0.0|\n",
      "|     July 31 2021|       Douglas|   CO|          Passenger|                               0|                                       1|                          1|                        83|            84|                     1.19|\n",
      "|      May 31 2018|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        59|            60|                     1.67|\n",
      "| November 30 2017|   Northampton|   PA|          Passenger|                               0|                                       1|                          1|                        66|            67|                     1.49|\n",
      "|    March 31 2018|        Nassau|   NY|          Passenger|                               1|                                       0|                          1|                        37|            38|                     2.63|\n",
      "|    March 31 2020|        DeKalb|   IN|          Passenger|                               1|                                       0|                          1|                         1|             2|                     50.0|\n",
      "|  January 31 2019|      Columbia|   WA|              Truck|                               0|                                       0|                          0|                     1,529|         1,529|                      0.0|\n",
      "| February 28 2017|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        73|            74|                     1.35|\n",
      "|September 30 2017|       Orleans|   LA|          Passenger|                               0|                                       1|                          1|                        45|            46|                     2.17|\n",
      "| December 31 2018|        Ramsey|   MN|          Passenger|                               1|                                       0|                          1|                        41|            42|                     2.38|\n",
      "| November 30 2020|      Manassas|   VA|          Passenger|                               0|                                       1|                          1|                         5|             6|                    16.67|\n",
      "| February 29 2020|    Montgomery|   AL|          Passenger|                               0|                                       1|                          1|                        38|            39|                     2.56|\n",
      "|   August 31 2019|     Albemarle|   VA|          Passenger|                               1|                                       0|                          1|                        23|            24|                     4.17|\n",
      "|      May 31 2020|        Monroe|   IL|          Passenger|                               1|                                       0|                          1|                         3|             4|                     25.0|\n",
      "| December 31 2021|     San Diego|   CA|          Passenger|                              17|                                       6|                         23|                     2,541|         2,564|                      0.9|\n",
      "|     June 30 2021|      Skamania|   WA|              Truck|                               0|                                       0|                          0|                     4,026|         4,026|                      0.0|\n",
      "|  January 31 2017|       Douglas|   WA|              Truck|                               0|                                       0|                          0|                    11,425|        11,425|                      0.0|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1722003383310,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "DOPcJASCZhOx",
    "outputId": "da984965-92f1-484d-b014-87481e79bc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|             Date|        County|State|Vehicle Primary Use|Battery Electric Vehicles (BEVs)|Plug-In Hybrid Electric Vehicles (PHEVs)|Electric Vehicle (EV) Total|Non-Electric Vehicle Total|Total Vehicles|Percent Electric Vehicles|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|September 30 2022|     Riverside|   CA|          Passenger|                               7|                                       0|                          7|                       460|           467|                      1.5|\n",
      "| December 31 2022|Prince William|   VA|          Passenger|                               1|                                       2|                          3|                       188|           191|                     1.57|\n",
      "|  January 31 2020|        Dakota|   MN|          Passenger|                               0|                                       1|                          1|                        32|            33|                     3.03|\n",
      "|     June 30 2022|         Ferry|   WA|              Truck|                               0|                                       0|                          0|                     3,575|         3,575|                      0.0|\n",
      "|     July 31 2021|       Douglas|   CO|          Passenger|                               0|                                       1|                          1|                        83|            84|                     1.19|\n",
      "|      May 31 2018|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        59|            60|                     1.67|\n",
      "| November 30 2017|   Northampton|   PA|          Passenger|                               0|                                       1|                          1|                        66|            67|                     1.49|\n",
      "|    March 31 2018|        Nassau|   NY|          Passenger|                               1|                                       0|                          1|                        37|            38|                     2.63|\n",
      "|    March 31 2020|        DeKalb|   IN|          Passenger|                               1|                                       0|                          1|                         1|             2|                     50.0|\n",
      "|  January 31 2019|      Columbia|   WA|              Truck|                               0|                                       0|                          0|                     1,529|         1,529|                      0.0|\n",
      "| February 28 2017|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        73|            74|                     1.35|\n",
      "|September 30 2017|       Orleans|   LA|          Passenger|                               0|                                       1|                          1|                        45|            46|                     2.17|\n",
      "| December 31 2018|        Ramsey|   MN|          Passenger|                               1|                                       0|                          1|                        41|            42|                     2.38|\n",
      "| November 30 2020|      Manassas|   VA|          Passenger|                               0|                                       1|                          1|                         5|             6|                    16.67|\n",
      "| February 29 2020|    Montgomery|   AL|          Passenger|                               0|                                       1|                          1|                        38|            39|                     2.56|\n",
      "|   August 31 2019|     Albemarle|   VA|          Passenger|                               1|                                       0|                          1|                        23|            24|                     4.17|\n",
      "|      May 31 2020|        Monroe|   IL|          Passenger|                               1|                                       0|                          1|                         3|             4|                     25.0|\n",
      "| December 31 2021|     San Diego|   CA|          Passenger|                              17|                                       6|                         23|                     2,541|         2,564|                      0.9|\n",
      "|     June 30 2021|      Skamania|   WA|              Truck|                               0|                                       0|                          0|                     4,026|         4,026|                      0.0|\n",
      "|  January 31 2017|       Douglas|   WA|              Truck|                               0|                                       0|                          0|                    11,425|        11,425|                      0.0|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"any\", subset=[\"state\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1722003413179,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "tnUQYj12Zm8A",
    "outputId": "988572f8-7140-4c69-b483-6852b270d51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|             Date|        County|State|Vehicle Primary Use|Battery Electric Vehicles (BEVs)|Plug-In Hybrid Electric Vehicles (PHEVs)|Electric Vehicle (EV) Total|Non-Electric Vehicle Total|Total Vehicles|Percent Electric Vehicles|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "|September 30 2022|     Riverside|   CA|          Passenger|                               7|                                       0|                          7|                       460|           467|                      1.5|\n",
      "| December 31 2022|Prince William|   VA|          Passenger|                               1|                                       2|                          3|                       188|           191|                     1.57|\n",
      "|  January 31 2020|        Dakota|   MN|          Passenger|                               0|                                       1|                          1|                        32|            33|                     3.03|\n",
      "|     June 30 2022|         Ferry|   WA|              Truck|                               0|                                       0|                          0|                     3,575|         3,575|                      0.0|\n",
      "|     July 31 2021|       Douglas|   CO|          Passenger|                               0|                                       1|                          1|                        83|            84|                     1.19|\n",
      "|      May 31 2018|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        59|            60|                     1.67|\n",
      "| November 30 2017|   Northampton|   PA|          Passenger|                               0|                                       1|                          1|                        66|            67|                     1.49|\n",
      "|    March 31 2018|        Nassau|   NY|          Passenger|                               1|                                       0|                          1|                        37|            38|                     2.63|\n",
      "|    March 31 2020|        DeKalb|   IN|          Passenger|                               1|                                       0|                          1|                         1|             2|                     50.0|\n",
      "|  January 31 2019|      Columbia|   WA|              Truck|                               0|                                       0|                          0|                     1,529|         1,529|                      0.0|\n",
      "| February 28 2017|          Maui|   HI|          Passenger|                               1|                                       0|                          1|                        73|            74|                     1.35|\n",
      "|September 30 2017|       Orleans|   LA|          Passenger|                               0|                                       1|                          1|                        45|            46|                     2.17|\n",
      "| December 31 2018|        Ramsey|   MN|          Passenger|                               1|                                       0|                          1|                        41|            42|                     2.38|\n",
      "| November 30 2020|      Manassas|   VA|          Passenger|                               0|                                       1|                          1|                         5|             6|                    16.67|\n",
      "| February 29 2020|    Montgomery|   AL|          Passenger|                               0|                                       1|                          1|                        38|            39|                     2.56|\n",
      "|   August 31 2019|     Albemarle|   VA|          Passenger|                               1|                                       0|                          1|                        23|            24|                     4.17|\n",
      "|      May 31 2020|        Monroe|   IL|          Passenger|                               1|                                       0|                          1|                         3|             4|                     25.0|\n",
      "| December 31 2021|     San Diego|   CA|          Passenger|                              17|                                       6|                         23|                     2,541|         2,564|                      0.9|\n",
      "|     June 30 2021|      Skamania|   WA|              Truck|                               0|                                       0|                          0|                     4,026|         4,026|                      0.0|\n",
      "|  January 31 2017|       Douglas|   WA|              Truck|                               0|                                       0|                          0|                    11,425|        11,425|                      0.0|\n",
      "+-----------------+--------------+-----+-------------------+--------------------------------+----------------------------------------+---------------------------+--------------------------+--------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1722003772481,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "WIEQWeo9Z3G4",
    "outputId": "7c764d12-45f4-4bbd-93fa-fab47851ba6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- _1: string (nullable = true)\n",
      " |    |-- _2: string (nullable = true)\n",
      " |    |-- _3: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      "\n",
      "+--------------------+----------+\n",
      "|                name|       dob|\n",
      "+--------------------+----------+\n",
      "|    {James, , Smith}|1991-04-01|\n",
      "|   {Michael, Rose, }|2000-05-19|\n",
      "|{Robert, , Williams}|1978-09-05|\n",
      "|{Maria, Anne, Jones}|1967-12-01|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "data=data = [(('James','','Smith'),'1991-04-01'),\n",
    "  (('Michael','Rose',''),'2000-05-19'),\n",
    "  (('Robert','','Williams'),'1978-09-05'),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01'),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17')]\n",
    "\n",
    "columns= [\"name\", \"dob\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1722004054105,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "IIcLtXn6bN_-",
    "outputId": "c4ca2799-f82a-41ca-bb7e-b3b270405e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+-----+---+\n",
      "|name                |dob       |year|month|day|\n",
      "+--------------------+----------+----+-----+---+\n",
      "|{James, , Smith}    |1991-04-01|1991|04   |01 |\n",
      "|{Michael, Rose, }   |2000-05-19|2000|05   |19 |\n",
      "|{Robert, , Williams}|1978-09-05|1978|09   |05 |\n",
      "|{Maria, Anne, Jones}|1967-12-01|1967|12   |01 |\n",
      "|{Jen, Mary, Brown}  |1980-02-17|1980|02   |17 |\n",
      "+--------------------+----------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df1 = df.withColumn('year', split(df['dob'], '-').getItem(0)) \\\n",
    "    .withColumn('month', split(df['dob'], '-').getItem(1)) \\\n",
    "    .withColumn('day', split(df['dob'], '-').getItem(2))\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oC3wDzbcrL8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1722004223568,
     "user": {
      "displayName": "Kavya Bhosale",
      "userId": "00774082643265486092"
     },
     "user_tz": -330
    },
    "id": "dUD4f974cPy5",
    "outputId": "da869936-e846-45d5-d9fc-3a35cd88c7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+-----+----+\n",
      "|name                |dob       |year      |month|day |\n",
      "+--------------------+----------+----------+-----+----+\n",
      "|{James, , Smith}    |1991-04-01|1991-04-01|NULL |NULL|\n",
      "|{Michael, Rose, }   |2000-05-19|2000-05-19|NULL |NULL|\n",
      "|{Robert, , Williams}|1978-09-05|1978-09-05|NULL |NULL|\n",
      "|{Maria, Anne, Jones}|1967-12-01|1967-12-01|NULL |NULL|\n",
      "|{Jen, Mary, Brown}  |1980-02-17|1980-02-17|NULL |NULL|\n",
      "+--------------------+----------+----------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_col = pyspark.sql.functions.split(df['dob'], ' -')\n",
    "df2 = df.withColumn('year', split_col.getItem(0)) \\\n",
    "    .withColumn('month', split_col.getItem(1)) \\\n",
    "    .withColumn('day', split_col.getItem(2))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhQG3WSQcvLE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1kKo1ug9nByWm_tGXYOuf5p2YjbPQuqjg",
     "timestamp": 1722004551635
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
